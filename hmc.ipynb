{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import scipy.io, scipy.interpolate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "Say we want to sample from some probability density $P(x)$.\n",
    "There are two especially important parts of MCMC sampling:\n",
    "\n",
    "* The **transition probability** $Q(x | y)$: given a state $x_k$, the next candidate $x_{k + 1}$ is generated by sampling from $Q(x | x_k)$.\n",
    "* The **accept/reject** criterion: accept $x_{k + 1}$ with probability $\\min(1, P(x_{k + 1})/P(x_k))$.\n",
    "\n",
    "Usually, $Q(x | y)$ = normal distribution with mean $y$.\n",
    "But this choice is arbitrary and we could use anything, so long as the transitions are reversible: $Q(x | y) = Q(y | x)$.\n",
    "\n",
    "**Hamiltonian Monte Carlo is a clever choice of transition probability.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamiltonian mechanics\n",
    "\n",
    "**Hamiltonian mechanics** is a particular way of describing classical physical systems.\n",
    "\n",
    "* **The players**: position $q$, momentum $p$, and the total energy $H(q, p)$ of the system\n",
    "* **The rules**: Hamilton's equations of motion,\n",
    "$$\\begin{align}\n",
    "\\dot q & = +\\frac{\\partial H}{\\partial p} \\\\\n",
    "\\dot p & = -\\frac{\\partial H}{\\partial q}\n",
    "\\end{align}$$\n",
    "* When $p = m\\dot q$, and $H = $ kinetic energy + potential energy, Hamilton's equations of motion are equivalent to Newton's.\n",
    "\n",
    "Some very important things:\n",
    "* The energy $H$ is conserved along trajectories of the ODE.\n",
    "* The volume in phase space is conserved.\n",
    "Take a \"blob\" $D$ of position/momentum pairs, now evolve them all for a time $t$ using Hamilton's equations; this gives a morphed blob, $D_t$.\n",
    "Then $\\mathrm{vol}(D) = \\mathrm{vol}(D_t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamiltonian Monte Carlo\n",
    "\n",
    "MCMC simulation works with any reversible transition kernel.\n",
    "The idea of HMC is to augment the state $q$ with a *pseudo-momentum* variable $p$ and use Hamiltonian dynamics to update both $q$ and $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some real data\n",
    "\n",
    "Let's try and apply this to David's data from last week.\n",
    "We're going to do a little more cleaning up to remove duplicate points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = scipy.io.loadmat('layers.mat')\n",
    "sx, sy = layers['psx_layers'][0], layers['psy_layers'][0]\n",
    "dx = np.sqrt(np.diff(sx)**2 + np.diff(sy)**2)\n",
    "x = np.hstack(([0], np.cumsum(dx)))[:5000]\n",
    "target_layer = layers['layer_14'][0][:5000]\n",
    "\n",
    "# Find any points that are duplicated or where there's data missing and remove them\n",
    "repeat_point_indices = np.where(dx < 1.0)[0] + 1\n",
    "no_data_indices = np.where(np.isnan(target_layer))[0]\n",
    "good_indices = set(range(5000)) - set(repeat_point_indices) - set(no_data_indices)\n",
    "indices = np.array(list(good_indices))\n",
    "indices.sort()\n",
    "\n",
    "x = x[indices]\n",
    "target_layer = target_layer[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_data = scipy.io.loadmat('vels.mat')\n",
    "vel_interpolater = scipy.interpolate.interp1d(more_data['dists'][0], more_data['vels'][0])\n",
    "velocity = vel_interpolater(x)\n",
    "acc_interpolater = scipy.interpolate.interp1d(more_data['acc_dists'][0], more_data['acc'][0])\n",
    "accumulation = acc_interpolater(x) * 1.4  # need a little cheating to help us along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "\n",
    "total_time = 725.0\n",
    "num_steps = 40\n",
    "\n",
    "accumulation_scale = 1.08 * np.ones(num_steps)\n",
    "velocity_scale = 1.05 * np.ones(num_steps)\n",
    "\n",
    "z = model.layer_depth(x, accumulation_scale, velocity_scale,\n",
    "                      accumulation, velocity, total_time, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x/1000, target_layer, color='k', label='Data')\n",
    "ax.plot(x/1000, z[num_steps - 1, :], color='b', label='Model')\n",
    "ax.set_xlabel(\"x (km)\")\n",
    "fig.legend()\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ_final = target_layer - z[-1, :]\n",
    "λ = model.adjoint_solve(x, accumulation_scale, velocity_scale,\n",
    "                        accumulation, velocity, z, λ_final, total_time, num_steps)\n",
    "\n",
    "print(\"Numerical range of adjoint state: ({}, {})\".format(np.min(λ), np.max(λ)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x/1000, λ[0, :], color='k')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dJ_da = model.sensitivity_ascale(x, z, λ, accumulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = total_time / num_steps\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(range(num_steps)) * dt, dJ_da, color='k')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = np.array([k/num_steps * (1 - k/num_steps) for k in range(num_steps)])\n",
    "dJ = np.dot(dJ_da, da) * dt\n",
    "print(\"{:e}\".format(dJ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_0 = model.mean_square_misfit(x, z[-1, :], target_layer)\n",
    "print(\"{:e}\".format(error_0))\n",
    "\n",
    "for k in range(20):\n",
    "    δ = 1.0/2**k\n",
    "    zk = model.layer_depth(x, accumulation_scale + δ * da, velocity_scale,\n",
    "                           accumulation, velocity, total_time, num_steps)\n",
    "    error = model.mean_square_misfit(x, zk[-1, :], target_layer)\n",
    "    \n",
    "    print(\"{:e}, {:e}\".format((error - error_0)/δ, dJ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dJ_du = model.sensitivity_uscale(x, z, λ, velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = total_time / num_steps\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(range(num_steps)) * dt, dJ_du, color='k')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du = -0.1 * np.ones(num_steps)\n",
    "dJ = np.dot(dJ_du, du) * dt\n",
    "print(\"{:e}\".format(dJ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_0 = model.mean_square_misfit(x, z[-1, :], target_layer)\n",
    "print(\"{:e}\".format(error_0))\n",
    "\n",
    "for k in range(20):\n",
    "    δ = 1.0/2**k\n",
    "    zk = model.layer_depth(x, accumulation_scale, velocity_scale + δ * du,\n",
    "                           accumulation, velocity, total_time, num_steps)\n",
    "    error = model.mean_square_misfit(x, zk[-1, :], target_layer)\n",
    "    \n",
    "    print(\"{:e}, {:e}\".format((error - error_0)/δ, dJ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
